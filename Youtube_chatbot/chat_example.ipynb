{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4ffdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586fb3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa07c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install FAISS-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a8d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_text_splitters import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42054aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_list=[{'text': 'Imagine you happen across a short movie script that',\n",
    "  'start': 1.14,\n",
    "  'duration': 2.836},\n",
    " {'text': 'describes a scene between a person and their AI assistant.',\n",
    "  'start': 3.976,\n",
    "  'duration': 3.164},\n",
    " {'text': \"The script has what the person asks the AI, but the AI's response has been torn off.\",\n",
    "  'start': 7.48,\n",
    "  'duration': 5.58},\n",
    " {'text': 'Suppose you also have this powerful magical machine that can take',\n",
    "  'start': 13.06,\n",
    "  'duration': 3.92},\n",
    " {'text': 'any text and provide a sensible prediction of what word comes next.',\n",
    "  'start': 16.98,\n",
    "  'duration': 3.98},\n",
    " {'text': 'You could then finish the script by feeding in what you have to the machine,',\n",
    "  'start': 21.5,\n",
    "  'duration': 4.006},\n",
    " {'text': \"seeing what it would predict to start the AI's answer,\",\n",
    "  'start': 25.506,\n",
    "  'duration': 2.862},\n",
    " {'text': 'and then repeating this over and over with a growing script completing the dialogue.',\n",
    "  'start': 28.368,\n",
    "  'duration': 4.372},\n",
    " {'text': \"When you interact with a chatbot, this is exactly what's happening.\",\n",
    "  'start': 33.38,\n",
    "  'duration': 3.1},\n",
    " {'text': 'A large language model is a sophisticated mathematical function',\n",
    "  'start': 37.02,\n",
    "  'duration': 3.681},\n",
    " {'text': 'that predicts what word comes next for any piece of text.',\n",
    "  'start': 40.701,\n",
    "  'duration': 3.279},\n",
    " {'text': 'Instead of predicting one word with certainty, though,',\n",
    "  'start': 44.38,\n",
    "  'duration': 3.022},\n",
    " {'text': 'what it does is assign a probability to all possible next words.',\n",
    "  'start': 47.402,\n",
    "  'duration': 3.518},\n",
    " {'text': 'To build a chatbot, you lay out some text that describes an interaction between a user',\n",
    "  'start': 51.62,\n",
    "  'duration': 5.18},\n",
    " {'text': 'and a hypothetical AI assistant, add on whatever the user types in as the first part of',\n",
    "  'start': 56.8,\n",
    "  'duration': 5.24},\n",
    " {'text': 'the interaction, and then have the model repeatedly predict the next word that such a',\n",
    "  'start': 62.04,\n",
    "  'duration': 5.12},\n",
    " {'text': \"hypothetical AI assistant would say in response, and that's what's presented to the user.\",\n",
    "  'start': 67.16,\n",
    "  'duration': 5.3},\n",
    " {'text': 'In doing this, the output tends to look a lot more natural if',\n",
    "  'start': 73.08,\n",
    "  'duration': 3.134},\n",
    " {'text': 'you allow it to select less likely words along the way at random.',\n",
    "  'start': 76.214,\n",
    "  'duration': 3.286},\n",
    " {'text': 'So what this means is even though the model itself is deterministic,',\n",
    "  'start': 80.14,\n",
    "  'duration': 3.48},\n",
    " {'text': \"a given prompt typically gives a different answer each time it's run.\",\n",
    "  'start': 83.62,\n",
    "  'duration': 3.48},\n",
    " {'text': 'Models learn how to make these predictions by processing an enormous amount of text,',\n",
    "  'start': 88.04,\n",
    "  'duration': 4.292},\n",
    " {'text': 'typically pulled from the internet.',\n",
    "  'start': 92.332,\n",
    "  'duration': 1.768},\n",
    " {'text': 'For a standard human to read the amount of text that was used to train GPT-3,',\n",
    "  'start': 94.1,\n",
    "  'duration': 5.371},\n",
    " {'text': 'for example, if they read non-stop 24-7, it would take over 2600 years.',\n",
    "  'start': 99.471,\n",
    "  'duration': 4.889},\n",
    " {'text': 'Larger models since then train on much, much more.',\n",
    "  'start': 104.72,\n",
    "  'duration': 2.62},\n",
    " {'text': 'You can think of training a little bit like tuning the dials on a big machine.',\n",
    "  'start': 108.2,\n",
    "  'duration': 3.58},\n",
    " {'text': 'The way that a language model behaves is entirely determined by these',\n",
    "  'start': 112.28,\n",
    "  'duration': 4.021},\n",
    " {'text': 'many different continuous values, usually called parameters or weights.',\n",
    "  'start': 116.301,\n",
    "  'duration': 4.079},\n",
    " {'text': 'Changing those parameters will change the probabilities',\n",
    "  'start': 121.02,\n",
    "  'duration': 3.079},\n",
    " {'text': 'that the model gives for the next word on a given input.',\n",
    "  'start': 124.099,\n",
    "  'duration': 3.081},\n",
    " {'text': 'What puts the large in large language model is how',\n",
    "  'start': 127.86,\n",
    "  'duration': 2.867},\n",
    " {'text': 'they can have hundreds of billions of these parameters.',\n",
    "  'start': 130.727,\n",
    "  'duration': 3.093},\n",
    " {'text': 'No human ever deliberately sets those parameters.',\n",
    "  'start': 135.2,\n",
    "  'duration': 2.84},\n",
    " {'text': 'Instead, they begin at random, meaning the model just outputs gibberish,',\n",
    "  'start': 138.44,\n",
    "  'duration': 4.203},\n",
    " {'text': \"but they're repeatedly refined based on many example pieces of text.\",\n",
    "  'start': 142.643,\n",
    "  'duration': 3.917},\n",
    " {'text': 'One of these training examples could be just a handful of words,',\n",
    "  'start': 147.14,\n",
    "  'duration': 3.516},\n",
    " {'text': 'or it could be thousands, but in either case, the way this works is to',\n",
    "  'start': 150.656,\n",
    "  'duration': 3.84},\n",
    " {'text': 'pass in all but the last word from that example into the model and',\n",
    "  'start': 154.496,\n",
    "  'duration': 3.624},\n",
    " {'text': 'compare the prediction that it makes with the true last word from the example.',\n",
    "  'start': 158.12,\n",
    "  'duration': 4.22},\n",
    " {'text': 'An algorithm called backpropagation is used to tweak all of the parameters',\n",
    "  'start': 163.26,\n",
    "  'duration': 4.133},\n",
    " {'text': 'in such a way that it makes the model a little more likely to choose',\n",
    "  'start': 167.393,\n",
    "  'duration': 3.803},\n",
    " {'text': 'the true last word and a little less likely to choose all the others.',\n",
    "  'start': 171.196,\n",
    "  'duration': 3.804},\n",
    " {'text': 'When you do this for many, many trillions of examples,',\n",
    "  'start': 175.74,\n",
    "  'duration': 3.01},\n",
    " {'text': 'not only does the model start to give more accurate predictions on the training data,',\n",
    "  'start': 178.75,\n",
    "  'duration': 4.708},\n",
    " {'text': \"but it also starts to make more reasonable predictions on text that it's never\",\n",
    "  'start': 183.458,\n",
    "  'duration': 4.325},\n",
    " {'text': 'seen before.', 'start': 187.783, 'duration': 0.657},\n",
    " {'text': 'Given the huge number of parameters and the enormous amount of training data,',\n",
    "  'start': 189.42,\n",
    "  'duration': 4.499},\n",
    " {'text': 'the scale of computation involved in training a large language model is mind-boggling.',\n",
    "  'start': 193.919,\n",
    "  'duration': 4.961},\n",
    " {'text': 'To illustrate, imagine that you could perform one',\n",
    "  'start': 199.6,\n",
    "  'duration': 2.685},\n",
    " {'text': 'billion additions and multiplications every single second.',\n",
    "  'start': 202.285,\n",
    "  'duration': 3.115},\n",
    " {'text': 'How long do you think it would take for you to do all of the',\n",
    "  'start': 206.06,\n",
    "  'duration': 3.266},\n",
    " {'text': 'operations involved in training the largest language models?',\n",
    "  'start': 209.326,\n",
    "  'duration': 3.214},\n",
    " {'text': 'Do you think it would take a year?',\n",
    "  'start': 213.46,\n",
    "  'duration': 1.579},\n",
    " {'text': 'Maybe something like 10,000 years?',\n",
    "  'start': 216.039,\n",
    "  'duration': 1.921},\n",
    " {'text': 'The answer is actually much more than that.',\n",
    "  'start': 219.02,\n",
    "  'duration': 1.78},\n",
    " {'text': \"It's well over 100 million years.\",\n",
    "  'start': 221.12,\n",
    "  'duration': 2.78},\n",
    " {'text': 'This is only part of the story, though.',\n",
    "  'start': 225.52,\n",
    "  'duration': 1.84},\n",
    " {'text': 'This whole process is called pre-training.',\n",
    "  'start': 227.54,\n",
    "  'duration': 1.68},\n",
    " {'text': 'The goal of auto-completing a random passage of text from the',\n",
    "  'start': 229.5,\n",
    "  'duration': 3.146},\n",
    " {'text': 'internet is very different from the goal of being a good AI assistant.',\n",
    "  'start': 232.646,\n",
    "  'duration': 3.554},\n",
    " {'text': 'To address this, chatbots undergo another type of training,',\n",
    "  'start': 236.88,\n",
    "  'duration': 3.2},\n",
    " {'text': 'just as important, called reinforcement learning with human feedback.',\n",
    "  'start': 240.08,\n",
    "  'duration': 3.68},\n",
    " {'text': 'Workers flag unhelpful or problematic predictions,',\n",
    "  'start': 244.48,\n",
    "  'duration': 3.018},\n",
    " {'text': \"and their corrections further change the model's parameters,\",\n",
    "  'start': 247.498,\n",
    "  'duration': 3.611},\n",
    " {'text': 'making them more likely to give predictions that users prefer.',\n",
    "  'start': 251.109,\n",
    "  'duration': 3.671},\n",
    " {'text': 'Looking back at the pre-training, though, this staggering amount of',\n",
    "  'start': 254.78,\n",
    "  'duration': 4.08},\n",
    " {'text': 'computation is only made possible by using special computer chips that',\n",
    "  'start': 258.86,\n",
    "  'duration': 4.26},\n",
    " {'text': 'are optimized for running many operations in parallel, known as GPUs.',\n",
    "  'start': 263.12,\n",
    "  'duration': 4.14},\n",
    " {'text': 'However, not all language models can be easily parallelized.',\n",
    "  'start': 268.12,\n",
    "  'duration': 3.5},\n",
    " {'text': 'Prior to 2017, most language models would process text one word at a time,',\n",
    "  'start': 272.08,\n",
    "  'duration': 4.737},\n",
    " {'text': 'but then a team of researchers at Google introduced a new model known as the transformer.',\n",
    "  'start': 276.817,\n",
    "  'duration': 5.623},\n",
    " {'text': \"Transformers don't read text from the start to the finish,\",\n",
    "  'start': 283.3,\n",
    "  'duration': 3.445},\n",
    " {'text': 'they soak it all in at once, in parallel.',\n",
    "  'start': 286.745,\n",
    "  'duration': 2.395},\n",
    " {'text': 'The very first step inside a transformer, and most other language models for that matter,',\n",
    "  'start': 289.9,\n",
    "  'duration': 4.7},\n",
    " {'text': 'is to associate each word with a long list of numbers.',\n",
    "  'start': 294.6,\n",
    "  'duration': 2.82},\n",
    " {'text': 'The reason for this is that the training process only works with continuous values,',\n",
    "  'start': 297.86,\n",
    "  'duration': 4.536},\n",
    " {'text': 'so you have to somehow encode language using numbers,',\n",
    "  'start': 302.396,\n",
    "  'duration': 2.916},\n",
    " {'text': 'and each of these lists of numbers may somehow encode the meaning of the',\n",
    "  'start': 305.312,\n",
    "  'duration': 3.942},\n",
    " {'text': 'corresponding word.', 'start': 309.254, 'duration': 1.026},\n",
    " {'text': 'What makes transformers unique is their reliance',\n",
    "  'start': 310.28,\n",
    "  'duration': 3.08},\n",
    " {'text': 'on a special operation known as attention.',\n",
    "  'start': 313.36,\n",
    "  'duration': 2.64},\n",
    " {'text': 'This operation gives all of these lists of numbers a chance to talk to one another',\n",
    "  'start': 316.98,\n",
    "  'duration': 4.704},\n",
    " {'text': 'and refine the meanings they encode based on the context around, all done in parallel.',\n",
    "  'start': 321.684,\n",
    "  'duration': 4.876},\n",
    " {'text': 'For example, the numbers encoding the word bank might be changed based on the',\n",
    "  'start': 327.4,\n",
    "  'duration': 4.307},\n",
    " {'text': 'context surrounding it to somehow encode the more specific notion of a riverbank.',\n",
    "  'start': 331.707,\n",
    "  'duration': 4.473},\n",
    " {'text': 'Transformers typically also include a second type of operation known',\n",
    "  'start': 337.28,\n",
    "  'duration': 3.749},\n",
    " {'text': 'as a feed-forward neural network, and this gives the model extra',\n",
    "  'start': 341.029,\n",
    "  'duration': 3.532},\n",
    " {'text': 'capacity to store more patterns about language learned during training.',\n",
    "  'start': 344.561,\n",
    "  'duration': 3.859},\n",
    " {'text': 'All of this data repeatedly flows through many different iterations of',\n",
    "  'start': 349.28,\n",
    "  'duration': 4.121},\n",
    " {'text': 'these two fundamental operations, and as it does so,',\n",
    "  'start': 353.401,\n",
    "  'duration': 3.077},\n",
    " {'text': 'the hope is that each list of numbers is enriched to encode whatever',\n",
    "  'start': 356.478,\n",
    "  'duration': 4.006},\n",
    " {'text': 'information might be needed to make an accurate prediction of what word',\n",
    "  'start': 360.484,\n",
    "  'duration': 4.18},\n",
    " {'text': 'follows in the passage.', 'start': 364.664, 'duration': 1.336},\n",
    " {'text': 'At the end, one final function is performed on the last vector in this sequence,',\n",
    "  'start': 367.0,\n",
    "  'duration': 4.534},\n",
    " {'text': 'which now has had a chance to be influenced by all the other context from the input text,',\n",
    "  'start': 371.534,\n",
    "  'duration': 5.039},\n",
    " {'text': 'as well as everything the model learned during training,',\n",
    "  'start': 376.573,\n",
    "  'duration': 3.191},\n",
    " {'text': 'to produce a prediction of the next word.',\n",
    "  'start': 379.764,\n",
    "  'duration': 2.296},\n",
    " {'text': \"Again, the model's prediction looks like a probability for every possible next word.\",\n",
    "  'start': 382.48,\n",
    "  'duration': 4.88},\n",
    " {'text': 'Although researchers design the framework for how each of these steps work,',\n",
    "  'start': 388.56,\n",
    "  'duration': 4.234},\n",
    " {'text': \"it's important to understand that the specific behavior is an emergent phenomenon\",\n",
    "  'start': 392.794,\n",
    "  'duration': 4.568},\n",
    " {'text': 'based on how those hundreds of billions of parameters are tuned during training.',\n",
    "  'start': 397.362,\n",
    "  'duration': 4.458},\n",
    " {'text': 'This makes it incredibly challenging to determine',\n",
    "  'start': 402.48,\n",
    "  'duration': 2.59},\n",
    " {'text': 'why the model makes the exact predictions that it does.',\n",
    "  'start': 405.07,\n",
    "  'duration': 2.85},\n",
    " {'text': 'What you can see is that when you use large language model predictions to autocomplete',\n",
    "  'start': 408.44,\n",
    "  'duration': 5.338},\n",
    " {'text': 'a prompt, the words that it generates are uncannily fluent, fascinating, and even useful.',\n",
    "  'start': 413.778,\n",
    "  'duration': 5.462},\n",
    " {'text': \"If you're a new viewer and you're curious about more details on how\",\n",
    "  'start': 425.719,\n",
    "  'duration': 3.107},\n",
    " {'text': 'transformers and attention work, boy do I have some material for you.',\n",
    "  'start': 428.826,\n",
    "  'duration': 3.153},\n",
    " {'text': 'One option is to jump into a series I made about deep learning,',\n",
    "  'start': 432.399,\n",
    "  'duration': 3.681},\n",
    " {'text': 'where we visualize and motivate the details of attention and all the other steps',\n",
    "  'start': 436.08,\n",
    "  'duration': 4.66},\n",
    " {'text': 'in a transformer.', 'start': 440.74, 'duration': 0.979},\n",
    " {'text': 'Also, on my second channel I just posted a talk I gave a couple',\n",
    "  'start': 442.099,\n",
    "  'duration': 3.43},\n",
    " {'text': 'months ago about this topic for the company TNG in Munich.',\n",
    "  'start': 445.529,\n",
    "  'duration': 3.11},\n",
    " {'text': 'Sometimes I actually prefer the content I make as a casual talk rather than a produced',\n",
    "  'start': 449.079,\n",
    "  'duration': 4.022},\n",
    " {'text': 'video, but I leave it up to you which one of these feels like the better follow-on.',\n",
    "  'start': 453.101,\n",
    "  'duration': 3.838}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cba6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dff83c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_id = \"Gfr50f6ZBvo\" # only the ID, not full URL\n",
    "# try:\n",
    "#     # If you don’t care which language, this returns the “best” one\n",
    "#     transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
    "\n",
    "#     # Flatten it to plain text\n",
    "#     transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)\n",
    "#     print(transcript)\n",
    "\n",
    "# except TranscriptsDisabled:\n",
    "#     print(\"No captions available for this video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c61367",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript=\" \".join(chunk[\"text\"] for chunk in transcript_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f21ba",
   "metadata": {},
   "source": [
    "Step 1b - Indexing (Text Splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c83c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "chunks = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57bd3938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chucnks[100]\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d842269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"person and their AI assistant. The script has what the person asks the AI, but the AI's response\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4897de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c1b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dda8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(\n",
    "    chunks, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7b4d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ca988ba7-a08a-49ee-98e7-3feca8592653',\n",
       " 1: '4ad3372b-3ec7-4491-9106-64742bc2394b',\n",
       " 2: '269e3c25-045b-480b-8e88-518a96c42132',\n",
       " 3: '057be560-551a-4277-8f21-3ce4f220ca52',\n",
       " 4: '80d81474-71ac-42f4-b94d-be150cf60a30',\n",
       " 5: '3c53a986-89a4-48fc-9ee7-2e644ce00a6f',\n",
       " 6: 'c31ab298-e489-47e6-a07d-847cf24455c3',\n",
       " 7: 'e496b7e2-551c-4716-81c0-28df7a286457',\n",
       " 8: '1542f870-a31c-4437-b0f5-c3bfea91418b',\n",
       " 9: '73381485-3a5b-42a4-bdc1-8556f37c8452',\n",
       " 10: 'f123cb35-f49e-4487-8df8-b39fe7a22fc4',\n",
       " 11: 'e443e742-5b4e-4b4b-bd67-709303e14a97',\n",
       " 12: 'f9e43d92-31ba-4358-aa1c-7c1e44c434ae',\n",
       " 13: '5e46f279-b145-4c9f-91d7-36708cd61f63',\n",
       " 14: 'dcc84ef2-e508-48ff-b544-2b3f9e261b48',\n",
       " 15: 'a5a3e6f5-170a-4519-8ad0-60a1b158a178',\n",
       " 16: 'f6d7f6a8-848d-48d7-b417-6e7b5f033537',\n",
       " 17: 'e911d60f-4f6c-4a1c-9776-16fe39427533',\n",
       " 18: 'ddd74f9e-aa92-43ea-a148-da5d819ef75b',\n",
       " 19: '3a882e9d-3d92-467a-afcc-774b37ad554e',\n",
       " 20: '5fc0b4b7-68e8-4639-9d56-c201f50fa882',\n",
       " 21: '182a3499-4db1-4a91-839b-203372faa5df',\n",
       " 22: '8f44ca69-ce67-4d6b-aae3-0b751bf4fa45',\n",
       " 23: '985e68b8-52e6-46bc-8e78-a0536d94199f',\n",
       " 24: 'f93f78c3-be33-45a6-b4c1-9539f660c391',\n",
       " 25: 'fd3918cb-f991-498b-9e4d-60316fb32fe9',\n",
       " 26: '4a6f72d6-245d-4c0e-808d-758f490ffd5c',\n",
       " 27: '7ef43710-7fcf-40cf-b54e-c27b83998b92',\n",
       " 28: 'a9a0c202-c5f1-4544-a5f4-169c247fb018',\n",
       " 29: '744b06d4-3c74-4877-9c9b-2bef67296738',\n",
       " 30: 'c8b06799-d514-450b-9ed2-c930f08d3cb1',\n",
       " 31: '61046d8d-6c5f-44e0-b39c-bc0b052f19f5',\n",
       " 32: 'a7d8c4f1-1a42-4ad4-80e5-0466f5be34ee',\n",
       " 33: '1ed5a17f-2657-482d-bc5e-de6d96d5b4f2',\n",
       " 34: 'ed226cd0-9346-4832-a8a9-448c32123c58',\n",
       " 35: '12c9835a-e387-4cfd-a587-d00007a30a71',\n",
       " 36: 'a7b6499c-5cf8-424c-be7e-a47ba531ad43',\n",
       " 37: 'a2f1d9b1-3a68-43dd-b07e-2e6ac40cda82',\n",
       " 38: 'f81bfb6b-01f6-4e76-8479-41190b13497b',\n",
       " 39: '360b0c27-7b66-453a-b242-9a93c7cb7f92',\n",
       " 40: 'a2273afd-c62c-4d24-ad82-ceed084a551f',\n",
       " 41: '9f5b5b92-4f3a-4bac-b9ee-bcc0198e7220',\n",
       " 42: '6d565bba-009b-4c15-b65c-021c861f307c',\n",
       " 43: 'd15e4af7-403a-4d70-8726-a4f36cbae8c2',\n",
       " 44: '7bd32ee1-f3bc-4076-8489-9063b1c4d8b7',\n",
       " 45: '2fd46da3-af40-47d1-b3eb-207e8bf69a4b',\n",
       " 46: '31e9aceb-85f8-4a08-abaa-aeb3a8bdf32a',\n",
       " 47: '14361608-eef4-45dd-b05e-987991cacd45',\n",
       " 48: 'f7d3d608-9ac3-421f-b768-969106f1b013',\n",
       " 49: '9a89d905-8187-471e-8b6f-04fadc87beb3',\n",
       " 50: '2b823941-5bd9-4feb-9c5a-0f296a296d2d',\n",
       " 51: '207b8c42-4fb7-413c-b8ff-e91cc54060c2',\n",
       " 52: '4d56a78f-3193-4c2b-8c46-28026efc6d3a',\n",
       " 53: 'd96c876f-0ec8-4f35-9a1d-94f9e0408c13',\n",
       " 54: 'e24d2d24-b660-491f-80bd-6e36a3ec7557',\n",
       " 55: '79b231b4-bf22-4ddb-970d-07a993e52ae9',\n",
       " 56: '9f598f13-76e7-4dcc-8f3b-d888df0f5372',\n",
       " 57: '45d7be22-2e42-4803-ab6f-dcbff225300b',\n",
       " 58: '80fbadf1-da35-4e76-8fda-dd7d6dd4f267',\n",
       " 59: 'dde84b8d-0b62-460e-a55c-589ae7a15b4d',\n",
       " 60: 'a34c1b72-ec25-4ed4-9ae0-fefe3e9f3cf5',\n",
       " 61: 'f800c86c-2879-463c-9612-d0d9c06dbb40',\n",
       " 62: '0debd108-57f5-4e71-886f-a17be38d804e',\n",
       " 63: '6e6f5b96-9a33-4e96-a3ac-fa6cc47232c4',\n",
       " 64: '0a3e6195-0c74-455b-9d89-e4bd1cde8c87',\n",
       " 65: 'ffcc2716-ffb9-4dee-8b7b-f49711400d5b',\n",
       " 66: 'd801bf90-893b-4949-a241-5ca1c0edd6c7',\n",
       " 67: '57071c32-3691-485e-bc75-454d24c37ea7',\n",
       " 68: 'c1c9d719-c845-4e5d-affe-0d015e7d07aa',\n",
       " 69: '0df7c161-9688-4ec7-a46e-6894d123be76',\n",
       " 70: '20c40641-e1de-47d9-82fb-8be4dac79e05',\n",
       " 71: '87c503a1-8482-4d72-83d2-b525a167c73e',\n",
       " 72: '751ed4d2-f260-4a95-891d-77021d72ce21',\n",
       " 73: 'f05633a2-2963-42b7-bd97-9371c5249ce5',\n",
       " 74: '86d2e9b2-ec01-452d-a9c4-94e122f822f4',\n",
       " 75: 'fd915cd2-0110-49e8-9b8f-f5f2c483c878',\n",
       " 76: 'd5529ec2-093d-4a8a-b6a6-3ab46ade1f02',\n",
       " 77: 'a64e6861-eb2f-4cbf-b9a0-cf17b51b5758',\n",
       " 78: '9cb31654-586e-4d53-82c9-1e06c8c9d9ee',\n",
       " 79: 'cac501cf-298f-4d84-bc6e-332f21276b17',\n",
       " 80: '148d5a5e-5beb-48a7-9594-81f7d7fdf7b7',\n",
       " 81: '3c8d51fc-187b-4e9e-aa7f-1c12c78fbcf4',\n",
       " 82: '201d1263-ae9d-41ef-8539-a5253627ae04',\n",
       " 83: 'c11dd4f8-c2a0-4d09-8763-90a77cf754b7',\n",
       " 84: '467992e2-25b1-4c32-aac5-2cdbde4eb971',\n",
       " 85: '9b080cfc-e537-4ade-aa87-ac5d1d4e5ac9',\n",
       " 86: '9c1f9668-cf81-4c90-93ae-537500bb9bf5',\n",
       " 87: 'c6e43f2c-5c64-4437-a525-2b7b21b066da',\n",
       " 88: '09f7e13b-bf46-456b-aaf0-9eae8c884a9f',\n",
       " 89: '463aa189-65c6-444f-beb6-1013beaa4da2',\n",
       " 90: '42fc0497-c58e-40cd-8639-0f131a808955',\n",
       " 91: '507a9be5-218c-48a8-83ba-5d00eaa1d878',\n",
       " 92: 'fe1a1038-50cc-41f9-b53d-13e1036b0655',\n",
       " 93: '1b2b2797-ed7c-4f86-b75a-f1135f25e217'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e42cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get_by_ids(['dc13173a-b0ab-4898-a81d-d8e8e5c7949a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0831ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64344abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000186761FEB50>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d845c2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='09f7e13b-bf46-456b-aaf0-9eae8c884a9f', metadata={}, page_content='a series I made about deep learning, where we visualize and motivate the details of attention and'),\n",
       " Document(id='20c40641-e1de-47d9-82fb-8be4dac79e05', metadata={}, page_content='feed-forward neural network, and this gives the model extra capacity to store more patterns about'),\n",
       " Document(id='ca988ba7-a08a-49ee-98e7-3feca8592653', metadata={}, page_content='Imagine you happen across a short movie script that describes a scene between a person and their AI'),\n",
       " Document(id='f7d3d608-9ac3-421f-b768-969106f1b013', metadata={}, page_content='of text from the internet is very different from the goal of being a good AI assistant. To address')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('What is deepmind')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7ebc0",
   "metadata": {},
   "source": [
    "Augmentated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b11d0b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import  load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "381f6b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms=HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "955e371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMS=ChatHuggingFace(llm=llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15fe3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMS=ChatGoogleGenerativeAI(model='gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "756ecb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      {context}\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57537f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "question          = \"is the topic of nuclear fusion discussed in this video? if yes then what was discussed\"\n",
    "retrieved_docs    = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "522a7679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='463aa189-65c6-444f-beb6-1013beaa4da2', metadata={}, page_content='of attention and all the other steps in a transformer. Also, on my second channel I just posted a'),\n",
       " Document(id='31e9aceb-85f8-4a08-abaa-aeb3a8bdf32a', metadata={}, page_content='over 100 million years. This is only part of the story, though. This whole process is called'),\n",
       " Document(id='ca988ba7-a08a-49ee-98e7-3feca8592653', metadata={}, page_content='Imagine you happen across a short movie script that describes a scene between a person and their AI'),\n",
       " Document(id='9c1f9668-cf81-4c90-93ae-537500bb9bf5', metadata={}, page_content=\"If you're a new viewer and you're curious about more details on how transformers and attention\")]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c13868d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"of attention and all the other steps in a transformer. Also, on my second channel I just posted a\\n\\nover 100 million years. This is only part of the story, though. This whole process is called\\n\\nImagine you happen across a short movie script that describes a scene between a person and their AI\\n\\nIf you're a new viewer and you're curious about more details on how transformers and attention\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea752024",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4fdb55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"\\n      You are a helpful assistant.\\n      Answer ONLY from the provided transcript context.\\n      If the context is insufficient, just say you don't know.\\n\\n      of attention and all the other steps in a transformer. Also, on my second channel I just posted a\\n\\nover 100 million years. This is only part of the story, though. This whole process is called\\n\\nImagine you happen across a short movie script that describes a scene between a person and their AI\\n\\nIf you're a new viewer and you're curious about more details on how transformers and attention\\n      Question: is the topic of nuclear fusion discussed in this video? if yes then what was discussed\\n    \")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd0994",
   "metadata": {},
   "source": [
    "Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08083748",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LLMS.invoke(final_prompt)\n",
    "print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
